{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef8ac189",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "444f814a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_SUP = 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "502b3850",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = \"./apriori/75000/75000-out2.csv\"\n",
    "\n",
    "def parse_to_df(file_name):\n",
    "    f = open(file_name)\n",
    "    lines = f.readlines()\n",
    "    first_line = lines[0].split(\",\")\n",
    "    columns = [i-1 for i in range(1, len(first_line))]\n",
    "    rows = []\n",
    "    index = []\n",
    "    for line in lines:\n",
    "        splt = list(map(int, line.strip().split(\",\")))\n",
    "        rows.append(splt[1:])\n",
    "        index.append(splt[0])\n",
    "    \n",
    "    return pd.DataFrame(rows, columns=columns, index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f32a9720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# given a set of frequent itemsets F and a candidate \n",
    "# frequent item set of size k, checks whether all\n",
    "# k-1 size subsets are in F\n",
    "def is_valid_candidate(F, u):\n",
    "    for elem in u:\n",
    "        if (u - {elem}) not in F:\n",
    "            return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "# Given a set of frequent itemsets F and a size k,\n",
    "# constructs all possible k+1 sized candidate itemsets\n",
    "def candidate_gen(F, k):\n",
    "    candidates = set()\n",
    "    \n",
    "    k_sized_sets = list(filter(lambda s: len(s) == k, F))\n",
    "    for (first, second) in itertools.combinations(k_sized_sets, r=2):\n",
    "        joined = first.union(second)\n",
    "        if len(joined) == k+1 and is_valid_candidate(F, joined):\n",
    "            candidates.add(frozenset(joined))\n",
    "\n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "658233dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = parse_to_df(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2f235c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_subset(row, s):\n",
    "    for elem in s:\n",
    "        if row[elem] == 0:\n",
    "            return False\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb104d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{frozenset({40}), frozenset({32}), frozenset({49}), frozenset({43}), frozenset({28}), frozenset({1}), frozenset({18}), frozenset({36}), frozenset({33}), frozenset({23}), frozenset({14}), frozenset({27}), frozenset({24}), frozenset({45}), frozenset({31}), frozenset({16}), frozenset({41}), frozenset({22}), frozenset({48}), frozenset({11}), frozenset({17}), frozenset({44}), frozenset({9}), frozenset({47}), frozenset({37}), frozenset({46}), frozenset({42}), frozenset({5}), frozenset({15}), frozenset({12}), frozenset({4}), frozenset({2}), frozenset({7}), frozenset({3}), frozenset({29}), frozenset({19}), frozenset({35}), frozenset({0})}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{frozenset({40}),\n",
       " frozenset({32}),\n",
       " frozenset({49}),\n",
       " frozenset({43}),\n",
       " frozenset({1}),\n",
       " frozenset({36}),\n",
       " frozenset({33}),\n",
       " frozenset({23}),\n",
       " frozenset({14}),\n",
       " frozenset({24}),\n",
       " frozenset({18, 35}),\n",
       " frozenset({27, 28}),\n",
       " frozenset({45}),\n",
       " frozenset({31}),\n",
       " frozenset({41}),\n",
       " frozenset({16}),\n",
       " frozenset({22}),\n",
       " frozenset({48}),\n",
       " frozenset({11}),\n",
       " frozenset({17}),\n",
       " frozenset({44}),\n",
       " frozenset({9}),\n",
       " frozenset({47}),\n",
       " frozenset({37}),\n",
       " frozenset({46}),\n",
       " frozenset({42}),\n",
       " frozenset({5}),\n",
       " frozenset({15}),\n",
       " frozenset({12}),\n",
       " frozenset({4}),\n",
       " frozenset({2}),\n",
       " frozenset({7}),\n",
       " frozenset({3}),\n",
       " frozenset({29}),\n",
       " frozenset({19}),\n",
       " frozenset({0})}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def apriori(T, minSup):\n",
    "    counts = {}\n",
    "    flags = {}\n",
    "    k = 2\n",
    "    I = T.index\n",
    "    n_rows = len(T.index)\n",
    "    F_cur = {frozenset({i}) for i in T.columns if T[i].sum() / n_rows >= minSup}\n",
    "    F = F_cur\n",
    "    \n",
    "    print(F_cur)\n",
    "    #print(F)\n",
    "    \"\"\"\n",
    "    print(n_rows)\n",
    "    print([T[i].sum() / n_rows for i in T.columns])\n",
    "    \"\"\"\n",
    "    while len(F_cur) > 0:\n",
    "        for iset in F_cur:\n",
    "            flags[iset] = True\n",
    "            \n",
    "        candidates = candidate_gen(F_cur, k-1)\n",
    "        #print(candidates)\n",
    "        for c in candidates:\n",
    "            counts[c] = 0\n",
    "        for idx in T.index:\n",
    "            row = T.loc[idx]\n",
    "            for c in candidates:\n",
    "                if check_subset(row, c):\n",
    "                    counts[c] += 1\n",
    "       \n",
    "        F_next = {c for c in candidates if counts[c] / n_rows >= minSup}\n",
    "        for s1 in F_cur:\n",
    "            for s2 in F_next:\n",
    "                if s1.issubset(s2):\n",
    "                    flags[s1] = False\n",
    "                    \n",
    "        F_cur = F_next\n",
    "        F = F.union(F_cur)\n",
    "        k += 1\n",
    "    \n",
    "    \n",
    "    return {iset for iset in F if flags[iset]}\n",
    "\n",
    "df = parse_to_df(data_file)\n",
    "apriori(df, MIN_SUP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8305f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
